{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_treinamento, _), (_, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento = X_treinamento.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento = tf.data.Dataset.from_tensor_slices(X_treinamento).shuffle(buffer_size=600000).batch(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerador\n",
    "#1--> 500 --> 500\n",
    "\n",
    "gerador = Sequential()\n",
    "gerador.add(Dense(units = 500, input_dim=100, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)))\n",
    "gerador.add(Dense(units = 500, input_dim=100, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)))\n",
    "gerador.add(Dense(units = 784, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)))\n",
    "gerador.add(Reshape((28, 28)))\n",
    "gerador.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminador = Sequential()\n",
    "discriminador.add(InputLayer(input_shape=(28,28)))\n",
    "discriminador.add(Flatten())\n",
    "discriminador.add(Dense(units=500, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)))\n",
    "discriminador.add(Dense(units=500, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)))\n",
    "discriminador.add(Dense(units=1, activation='sigmoid', kernel_regularizer=L1L2(1e-5, 1e-5)))\n",
    "discriminador.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "  total_loss = real_loss + fake_loss\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images):\n",
    "  noise = tf.random.normal([256, noise_dim])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = gerador(noise, training = True)\n",
    "\n",
    "    real_output = discriminador(images, training = True)\n",
    "    fake_output = discriminador(generated_images, training = True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, gerador.trainable_variables)\n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminador.trainable_variables)\n",
    "\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, gerador.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminador.trainable_variables))\n",
    "\n",
    "  return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "  for image_batch in X_treinamento:\n",
    "    gen_loss_batch, disc_loss_batch = train_step(image_batch)\n",
    "  print(f'Ã‰poca {epoch} | gen_loss: {gen_loss_batch} disc_loss {disc_loss_batch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostras = np.random.normal(size=(20, 100))\n",
    "previsao = gerador.predict(amostras)\n",
    "for i in range(previsao.shape[0]):\n",
    "  plt.imshow(previsao[i, :], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
